{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set transformer cache to \"./.transformer_cache\"\n",
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = './cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerModel, TimeSeriesTransformerForPrediction\n",
    "from transformers import AdamW\n",
    "from sklearn.metrics import roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admissionid</th>\n",
       "      <th>hour</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>urine</th>\n",
       "      <th>measuredat</th>\n",
       "      <th>baseline_creatinine</th>\n",
       "      <th>temp</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>systolic_ABP</th>\n",
       "      <th>mean_ABP</th>\n",
       "      <th>...</th>\n",
       "      <th>bilirubine_change</th>\n",
       "      <th>leukocyten_change</th>\n",
       "      <th>hematocryt_change</th>\n",
       "      <th>lactate_change</th>\n",
       "      <th>sodium_change</th>\n",
       "      <th>ph_change</th>\n",
       "      <th>icu_days</th>\n",
       "      <th>stage_12hours</th>\n",
       "      <th>AKI</th>\n",
       "      <th>AKI_12hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>765.0</td>\n",
       "      <td>0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>34.017647</td>\n",
       "      <td>76.600000</td>\n",
       "      <td>134.600000</td>\n",
       "      <td>94.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>43200000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>34.252632</td>\n",
       "      <td>72.769231</td>\n",
       "      <td>136.307692</td>\n",
       "      <td>92.615385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.100001</td>\n",
       "      <td>0.027054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.741071</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>94.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>86400000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>145.750000</td>\n",
       "      <td>100.916667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.013929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.428571</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>129600000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>36.250000</td>\n",
       "      <td>82.166667</td>\n",
       "      <td>132.181711</td>\n",
       "      <td>89.533326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.700001</td>\n",
       "      <td>-0.025500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>905.0</td>\n",
       "      <td>172800000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>81.583333</td>\n",
       "      <td>152.595701</td>\n",
       "      <td>103.619476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.550000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   admissionid  hour  creatinine   urine  measuredat  baseline_creatinine  \\\n",
       "0            9     0       103.0   765.0           0                 94.0   \n",
       "1            9     1        94.0   850.0    43200000                 94.0   \n",
       "2            9     2        94.0   475.0    86400000                 94.0   \n",
       "3            9     3        98.0  1010.0   129600000                 94.0   \n",
       "4            9     4        98.0   905.0   172800000                 94.0   \n",
       "\n",
       "        temp  heart_rate  systolic_ABP    mean_ABP  ...  bilirubine_change  \\\n",
       "0  34.017647   76.600000    134.600000   94.800000  ...                0.0   \n",
       "1  34.252632   72.769231    136.307692   92.615385  ...                0.0   \n",
       "2  36.600000   89.000000    145.750000  100.916667  ...                0.0   \n",
       "3  36.250000   82.166667    132.181711   89.533326  ...                0.0   \n",
       "4  37.000000   81.583333    152.595701  103.619476  ...                0.0   \n",
       "\n",
       "   leukocyten_change  hematocryt_change  lactate_change  sodium_change  \\\n",
       "0           0.000000           0.000000             0.0       0.000000   \n",
       "1          -2.100001           0.027054             0.0       0.741071   \n",
       "2           0.000000          -0.013929             0.0      -0.428571   \n",
       "3           5.700001          -0.025500             0.0       0.800000   \n",
       "4           0.000000           0.003000             0.0      -0.550000   \n",
       "\n",
       "   ph_change  icu_days  stage_12hours  AKI  AKI_12hours  \n",
       "0       0.00       0.0            0.0    0          0.0  \n",
       "1      -0.02       0.5            0.0    0          0.0  \n",
       "2       0.00       1.0            0.0    0          0.0  \n",
       "3       0.00       1.5            0.0    0          0.0  \n",
       "4       0.00       2.0            0.0    0          0.0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train_data_12h.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test_data_12h.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the categorical features from the dataframe\n",
    "categorical_features = df.select_dtypes(include=['object', 'bool'])\n",
    "\n",
    "# Apply label encoder to the categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_categorical_features = categorical_features.apply(label_encoder.fit_transform)\n",
    "\n",
    "# Combine the encoded categorical features with the numerical features\n",
    "numerical_features = df.select_dtypes(include=['float', 'int'])\n",
    "encoded_dataset = pd.concat([numerical_features, encoded_categorical_features], axis=1)\n",
    "\n",
    "# Apply label encoder to test\n",
    "categorical_features_test = test_df.select_dtypes(include=['object', 'bool'])\n",
    "encoded_categorical_features_test = categorical_features_test.apply(label_encoder.fit_transform)\n",
    "numerical_features_test = test_df.select_dtypes(include=['float', 'int'])\n",
    "encoded_dataset_test = pd.concat([numerical_features_test, encoded_categorical_features_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Length of AKI-6hours: 102.77642206564701\n",
      "Average Count of 0s: 53.44526550953772\n",
      "Average Count of 1s: 49.3311565561093\n",
      "Minimum Length of AKI-6hours: 2\n",
      "Maximum Length of AKI-6hours: 1823\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty lists to store the results\n",
    "average_length = []\n",
    "average_count_0 = []\n",
    "average_count_1 = []\n",
    "\n",
    "# Iterate through the encoded_dataset\n",
    "for admissionid, admissionid_df in encoded_dataset.groupby('admissionid'):\n",
    "    # print(admissionid)\n",
    "    # print(admissionid_df['AKI_6hours'].values)\n",
    "    \n",
    "    # Calculate the average length of AKI-6hours\n",
    "    length = len(admissionid_df['AKI_12hours'].values)\n",
    "    average_length.append(length)\n",
    "    \n",
    "    # Calculate the average count of 0s and 1s\n",
    "    count_0 = np.count_nonzero(admissionid_df['AKI_12hours'].values == 0)\n",
    "    count_1 = np.count_nonzero(admissionid_df['AKI_12hours'].values == 1)\n",
    "    average_count_0.append(count_0)\n",
    "    average_count_1.append(count_1)\n",
    "    \n",
    "# Calculate the overall averages\n",
    "overall_average_length = np.mean(average_length)\n",
    "overall_average_count_0 = np.mean(average_count_0)\n",
    "overall_average_count_1 = np.mean(average_count_1)\n",
    "\n",
    "# Print the results\n",
    "print(\"Average Length of AKI-6hours:\", overall_average_length)\n",
    "print(\"Average Count of 0s:\", overall_average_count_0)\n",
    "print(\"Average Count of 1s:\", overall_average_count_1)\n",
    "print(\"Minimum Length of AKI-6hours:\", np.min(average_length))\n",
    "print(\"Maximum Length of AKI-6hours:\", np.max(average_length))\n",
    "\n",
    "# Use these counts to determine the context length and prediction length\n",
    "# 24 context length, 8 prediction length, 4 lag sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_dataset(dataset, context_length, prediction_length, lag_length):\n",
    "    # Initialize empty lists to store the dataset components\n",
    "    all_past_values = []\n",
    "    all_future_values = []\n",
    "    all_past_time_features = []\n",
    "    all_future_time_features = []\n",
    "    all_past_values_mask = []\n",
    "\n",
    "    features_columns = ['creatinine', 'urine', 'measuredat', 'temp', 'heart_rate', 'systolic_ABP', 'mean_ABP', 'dystolic_ABP', 'resp_rate', 'glucose', 'hema', 'calcium', 'kalium', 'ox_sat', 'thrombo', 'bilirubine', 'leukocyten', 'hematocryt', 'lactate', 'sodium', 'ph']\n",
    "    temporal_columns = ['creatinine_change', 'urine_change', 'temp_change', 'heart_rate_change', 'systolic_ABP_change', 'mean_ABP_change', 'dystolic_ABP_change', 'resp_rate_change', 'glucose_change', 'hema_change', 'calcium_change', 'kalium_change', 'ox_sat_change', 'thrombo_change', 'bilirubine_change', 'leukocyten_change', 'hematocryt_change', 'lactate_change', 'sodium_change', 'ph_change']\n",
    "    extra_features = ['has_sepsis', 'has_ventilation', 'nsaid_taken', 'vassopressor_taken', 'acei_taken', 'arb_taken', 'cardiac_surgery', 'traumatology', 'vascular_surgery', 'gastroenterology_surgery', 'lungs_oncology_surgery', 'oncology_surgery', 'neuro_surgery', 'gender_Man', 'gender_Vrouw', 'agegroup', 'weightgroup', 'heightgroup']\n",
    "\n",
    "    # Iterate over admission IDs\n",
    "    for admission_id in dataset['admissionid'].unique():\n",
    "        # Get the sample for the current admission ID\n",
    "        sample_patient = dataset[dataset['admissionid'] == admission_id].copy()\n",
    "\n",
    "        # Check if the sample patient has enough AKI_6hours values\n",
    "        if len(sample_patient['AKI_12hours']) >= context_length + lag_length + prediction_length:\n",
    "            # Split the dataframe into the required components\n",
    "            past_values = sample_patient['AKI_12hours'].values[:context_length + lag_length]\n",
    "            future_values = sample_patient['AKI_12hours'].values[context_length + lag_length:context_length + lag_length + prediction_length]\n",
    "            sample_patient.drop(columns=['admissionid', 'patientid', 'admissionyeargroup', 'comparison_result', 'stage_12hours', 'AKI', 'AKI_12hours'], inplace=True)\n",
    "            past_time_features = sample_patient[features_columns + extra_features].values[:context_length + lag_length]\n",
    "            future_time_features = sample_patient[features_columns + extra_features].values[context_length + lag_length:context_length + lag_length + prediction_length]\n",
    "            past_values_mask = np.ones(context_length)\n",
    "            \n",
    "            # Append the components to the respective lists\n",
    "            all_past_values.append(past_values)\n",
    "            all_future_values.append(future_values)\n",
    "            all_past_time_features.append(past_time_features)\n",
    "            all_future_time_features.append(future_time_features)\n",
    "            all_past_values_mask.append(past_values_mask)\n",
    "\n",
    "    # Convert the lists to tensors\n",
    "    all_past_values_tensor = torch.tensor(all_past_values, dtype=torch.float32)\n",
    "    all_future_values_tensor = torch.tensor(all_future_values, dtype=torch.float32)\n",
    "    all_past_time_features_tensor = torch.tensor(all_past_time_features, dtype=torch.float32)\n",
    "    all_future_time_features_tensor = torch.tensor(all_future_time_features, dtype=torch.float32)\n",
    "    all_past_values_mask_tensor = torch.tensor(all_past_values_mask, dtype=torch.float32)\n",
    "\n",
    "        # Print the shapes of the tensors\n",
    "    print(\"All Past Values Tensor Shape:\", all_past_values_tensor.shape)\n",
    "    print(\"All Future Values Tensor Shape:\", all_future_values_tensor.shape)\n",
    "    print(\"All Past Time Features Tensor Shape:\", all_past_time_features_tensor.shape)\n",
    "    print(\"All Future Time Features Tensor Shape:\", all_future_time_features_tensor.shape)\n",
    "\n",
    "    return {\"past_values\": all_past_values_tensor, \"future_values\":  all_future_values_tensor, \"past_features\": all_past_time_features_tensor, \"future_features\": all_future_time_features_tensor, \"past_values_mask\": all_past_values_mask_tensor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_columns = ['creatinine', 'urine', 'measuredat', 'temp', 'heart_rate', 'systolic_ABP', 'mean_ABP', 'dystolic_ABP', 'resp_rate', 'glucose', 'hema', 'calcium', 'kalium', 'ox_sat', 'thrombo', 'bilirubine', 'leukocyten', 'hematocryt', 'lactate', 'sodium', 'ph', 'creatinine_change', 'urine_change', 'temp_change', 'heart_rate_change', 'systolic_ABP_change', 'mean_ABP_change', 'dystolic_ABP_change', 'resp_rate_change', 'glucose_change', 'hema_change', 'calcium_change', 'kalium_change', 'ox_sat_change', 'thrombo_change', 'bilirubine_change', 'leukocyten_change', 'hematocryt_change', 'lactate_change', 'sodium_change', 'ph_change']\n",
    "len(features_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_features = ['has_sepsis', 'has_ventilation', 'nsaid_taken', 'vassopressor_taken', 'antimicrobiotic_taken', 'acei_taken', 'arb_taken', 'cardiac_surgery', 'traumatology', 'vascular_surgery', 'gastroenterology_surgery', 'lungs_oncology_surgery', 'oncology_surgery', 'neuro_surgery', 'gender_Man', 'gender_Vrouw', 'agegroup', 'weightgroup', 'heightgroup', 'Death']\n",
    "len(extra_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Past Values Tensor Shape: torch.Size([2300, 70])\n",
      "All Future Values Tensor Shape: torch.Size([2300, 12])\n",
      "All Past Time Features Tensor Shape: torch.Size([2300, 70, 60])\n",
      "All Future Time Features Tensor Shape: torch.Size([2300, 12, 60])\n",
      "All Past Values Tensor Shape: torch.Size([188, 70])\n",
      "All Future Values Tensor Shape: torch.Size([188, 12])\n",
      "All Past Time Features Tensor Shape: torch.Size([188, 70, 60])\n",
      "All Future Time Features Tensor Shape: torch.Size([188, 12, 60])\n"
     ]
    }
   ],
   "source": [
    "context_length = 16\n",
    "prediction_length = 4\n",
    "lag_length = 2\n",
    "train_data = make_train_dataset(encoded_dataset, context_length, prediction_length, lag_length)\n",
    "test_data = make_train_dataset(encoded_dataset_test, context_length, prediction_length, lag_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorDataset\n",
    "train_dataset = TensorDataset(train_data[\"past_values\"], train_data[\"future_values\"], train_data[\"past_features\"], train_data[\"future_features\"], train_data[\"past_values_mask\"])\n",
    "test_dataset = TensorDataset(test_data[\"past_values\"], test_data[\"future_values\"], test_data[\"past_features\"], test_data[\"future_features\"], test_data[\"past_values_mask\"])\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesTransformerConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"cardinality\": [\n",
      "    0\n",
      "  ],\n",
      "  \"context_length\": 64,\n",
      "  \"d_model\": 128,\n",
      "  \"decoder_attention_heads\": 4,\n",
      "  \"decoder_ffn_dim\": 512,\n",
      "  \"decoder_layerdrop\": 0.1,\n",
      "  \"decoder_layers\": 4,\n",
      "  \"distribution_output\": \"student_t\",\n",
      "  \"dropout\": 0.1,\n",
      "  \"embedding_dimension\": [\n",
      "    0\n",
      "  ],\n",
      "  \"encoder_attention_heads\": 2,\n",
      "  \"encoder_ffn_dim\": 512,\n",
      "  \"encoder_layerdrop\": 0.1,\n",
      "  \"encoder_layers\": 4,\n",
      "  \"feature_size\": 66,\n",
      "  \"init_std\": 0.02,\n",
      "  \"input_size\": 1,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"lags_sequence\": [\n",
      "    1,\n",
      "    2,\n",
      "    4,\n",
      "    6\n",
      "  ],\n",
      "  \"loss\": \"nll\",\n",
      "  \"model_type\": \"time_series_transformer\",\n",
      "  \"num_dynamic_real_features\": 0,\n",
      "  \"num_parallel_samples\": 100,\n",
      "  \"num_static_categorical_features\": 0,\n",
      "  \"num_static_real_features\": 0,\n",
      "  \"num_time_features\": 60,\n",
      "  \"prediction_length\": 12,\n",
      "  \"scaling\": \"mean\",\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"use_cache\": true\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initializing a default Time Series Transformer configuration\n",
    "configuration = TimeSeriesTransformerConfig(context_length=context_length, lags_sequence=[1, 2], prediction_length=prediction_length, num_time_features=39,\n",
    "                                            encoder_layers=4, decoder_layers=4, encoder_attention_heads=2, decoder_attention_heads=4,\n",
    "                                            d_model=128, encoder_ffn_dim=512, decoder_ffn_dim=512,\n",
    "\n",
    ")\n",
    "\n",
    "# Randomly initializing a model (with random weights) from the configuration\n",
    "model = TimeSeriesTransformerForPrediction(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "print(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 1888643\n",
      "Total trainable parameters: 1869187\n"
     ]
    }
   ],
   "source": [
    "# print count of parameters in the model\n",
    "print(\"Number of parameters:\", model.num_parameters())\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total trainable parameters:\", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Vrije\\DL2\\DL2\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: -9.9663\n",
      "Epoch 2/10, Loss: -10.0026\n",
      "Epoch 3/10, Loss: -10.0261\n",
      "Epoch 4/10, Loss: -10.0334\n",
      "Epoch 5/10, Loss: -10.0325\n",
      "Epoch 6/10, Loss: -10.0301\n",
      "Epoch 7/10, Loss: -9.9290\n",
      "Epoch 8/10, Loss: -9.9676\n",
      "Epoch 9/10, Loss: -9.9994\n",
      "Epoch 10/10, Loss: -9.9873\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    total_batches = len(train_dataloader)\n",
    "\n",
    "    # Iterate over the batches\n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        past_values_batch, future_values_batch, past_time_features_batch, future_time_features_batch, past_values_mask_batch = batch\n",
    "        \n",
    "        # # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            past_values=past_values_batch,\n",
    "            past_time_features=past_time_features_batch,\n",
    "            past_observed_mask=past_values_mask_batch,\n",
    "            future_values=future_values_batch,\n",
    "            future_time_features=future_time_features_batch,\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate the loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Print batch loss\n",
    "        # print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx+1}/{total_batches}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Print the average loss for the epoch\n",
    "    average_loss = running_loss / total_batches\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {average_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8075, F1 Score: 0.7616\n"
     ]
    }
   ],
   "source": [
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for batch_idx, batch in enumerate(test_dataloader):\n",
    "    past_values_batch, future_values_batch, past_time_features_batch, future_time_features_batch, past_values_mask_batch = batch\n",
    "    outputs = model.generate(\n",
    "        past_values=past_values_batch,\n",
    "        past_time_features=past_time_features_batch,\n",
    "        past_observed_mask=past_values_mask_batch,\n",
    "        future_time_features=future_time_features_batch,\n",
    "    )\n",
    "\n",
    "    mean_prediction = outputs.sequences.mean(dim=1)\n",
    "\n",
    "    # Round the predictions to nearest integer\n",
    "    predictions = torch.round(mean_prediction)\n",
    "    targets = future_values_batch\n",
    "\n",
    "    # Append predictions and targets to lists\n",
    "    all_predictions.append(predictions)\n",
    "    all_targets.append(targets)\n",
    "\n",
    "# Concatenate the predictions and targets tensors\n",
    "all_predictions = torch.cat(all_predictions, dim=0)\n",
    "all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "# Calculate AUC and F1 score\n",
    "auc = roc_auc_score(all_targets.cpu().numpy(), all_predictions.cpu().numpy())\n",
    "f1 = f1_score(all_targets.cpu().numpy(), all_predictions.cpu().numpy(), average='weighted')\n",
    "\n",
    "# Print the AUC and F1 score\n",
    "print(f\"AUC: {auc:.4f}, F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying without temporal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Past Values Tensor Shape: torch.Size([2300, 70])\n",
      "All Future Values Tensor Shape: torch.Size([2300, 12])\n",
      "All Past Time Features Tensor Shape: torch.Size([2300, 70, 41])\n",
      "All Future Time Features Tensor Shape: torch.Size([2300, 12, 41])\n",
      "All Past Values Tensor Shape: torch.Size([188, 70])\n",
      "All Future Values Tensor Shape: torch.Size([188, 12])\n",
      "All Past Time Features Tensor Shape: torch.Size([188, 70, 41])\n",
      "All Future Time Features Tensor Shape: torch.Size([188, 12, 41])\n"
     ]
    }
   ],
   "source": [
    "train_data_noExtra = make_train_dataset(encoded_dataset, context_length, prediction_length, lag_length)\n",
    "test_data_noExtra = make_train_dataset(encoded_dataset_test, context_length, prediction_length, lag_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorDataset\n",
    "train_dataset_noExtra = TensorDataset(train_data_noExtra[\"past_values\"], train_data_noExtra[\"future_values\"], train_data_noExtra[\"past_features\"], train_data_noExtra[\"future_features\"], train_data_noExtra[\"past_values_mask\"])\n",
    "test_dataset_noExtra = TensorDataset(test_data_noExtra[\"past_values\"], test_data_noExtra[\"future_values\"], test_data_noExtra[\"past_features\"], test_data_noExtra[\"future_features\"], test_data_noExtra[\"past_values_mask\"])\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 16\n",
    "train_dataloader_noExtra = DataLoader(train_dataset_noExtra, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader_noExtra = DataLoader(test_dataset_noExtra, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesTransformerConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"cardinality\": [\n",
      "    0\n",
      "  ],\n",
      "  \"context_length\": 64,\n",
      "  \"d_model\": 128,\n",
      "  \"decoder_attention_heads\": 4,\n",
      "  \"decoder_ffn_dim\": 512,\n",
      "  \"decoder_layerdrop\": 0.1,\n",
      "  \"decoder_layers\": 4,\n",
      "  \"distribution_output\": \"student_t\",\n",
      "  \"dropout\": 0.1,\n",
      "  \"embedding_dimension\": [\n",
      "    0\n",
      "  ],\n",
      "  \"encoder_attention_heads\": 2,\n",
      "  \"encoder_ffn_dim\": 512,\n",
      "  \"encoder_layerdrop\": 0.1,\n",
      "  \"encoder_layers\": 4,\n",
      "  \"feature_size\": 47,\n",
      "  \"init_std\": 0.02,\n",
      "  \"input_size\": 1,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"lags_sequence\": [\n",
      "    1,\n",
      "    2,\n",
      "    4,\n",
      "    6\n",
      "  ],\n",
      "  \"loss\": \"nll\",\n",
      "  \"model_type\": \"time_series_transformer\",\n",
      "  \"num_dynamic_real_features\": 0,\n",
      "  \"num_parallel_samples\": 100,\n",
      "  \"num_static_categorical_features\": 0,\n",
      "  \"num_static_real_features\": 0,\n",
      "  \"num_time_features\": 41,\n",
      "  \"prediction_length\": 12,\n",
      "  \"scaling\": \"mean\",\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"use_cache\": true\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initializing a default Time Series Transformer configuration\n",
    "configuration2 = TimeSeriesTransformerConfig(context_length=context_length, lags_sequence=[1, 2, 4, 6], prediction_length=prediction_length, num_time_features=41,\n",
    "                                            encoder_layers=4, decoder_layers=4, encoder_attention_heads=2, decoder_attention_heads=4,\n",
    "                                            d_model=128, encoder_ffn_dim=512, decoder_ffn_dim=512,\n",
    "\n",
    ")\n",
    "\n",
    "# Randomly initializing a model (with random weights) from the configuration\n",
    "model2 = TimeSeriesTransformerForPrediction(configuration2)\n",
    "\n",
    "# Accessing the model configuration\n",
    "# configuration = model.config\n",
    "print(configuration2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Vrije\\DL2\\DL2\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: -9.9325\n",
      "Epoch 2/10, Loss: -10.0055\n",
      "Epoch 3/10, Loss: -10.0194\n",
      "Epoch 4/10, Loss: -10.0422\n",
      "Epoch 5/10, Loss: -10.0353\n",
      "Epoch 6/10, Loss: -10.0474\n",
      "Epoch 7/10, Loss: -10.0382\n",
      "Epoch 8/10, Loss: -10.0501\n",
      "Epoch 9/10, Loss: -10.0505\n",
      "Epoch 10/10, Loss: -10.0564\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "optimizer = AdamW(model2.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    total_batches = len(train_dataloader_noExtra)\n",
    "\n",
    "    # Iterate over the batches\n",
    "    for batch_idx, batch in enumerate(train_dataloader_noExtra):\n",
    "        past_values_batch, future_values_batch, past_time_features_batch, future_time_features_batch, past_values_mask_batch = batch\n",
    "        \n",
    "        # # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model2(\n",
    "            past_values=past_values_batch,\n",
    "            past_time_features=past_time_features_batch,\n",
    "            past_observed_mask=past_values_mask_batch,\n",
    "            future_values=future_values_batch,\n",
    "            future_time_features=future_time_features_batch,\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate the loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Print batch loss\n",
    "        # print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx+1}/{total_batches}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Print the average loss for the epoch\n",
    "    average_loss = running_loss / total_batches\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {average_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.6717, F1 Score: 0.5103\n"
     ]
    }
   ],
   "source": [
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for batch_idx, batch in enumerate(test_dataloader_noExtra):\n",
    "    past_values_batch, future_values_batch, past_time_features_batch, future_time_features_batch, past_values_mask_batch = batch\n",
    "    outputs = model2.generate(\n",
    "        past_values=past_values_batch,\n",
    "        past_time_features=past_time_features_batch,\n",
    "        past_observed_mask=past_values_mask_batch,\n",
    "        future_time_features=future_time_features_batch,\n",
    "    )\n",
    "\n",
    "    mean_prediction = outputs.sequences.mean(dim=1)\n",
    "\n",
    "    # Round the predictions to nearest integer\n",
    "    predictions = torch.round(mean_prediction)\n",
    "    targets = future_values_batch\n",
    "\n",
    "    # Append predictions and targets to lists\n",
    "    all_predictions.append(predictions)\n",
    "    all_targets.append(targets)\n",
    "\n",
    "# Concatenate the predictions and targets tensors\n",
    "all_predictions = torch.cat(all_predictions, dim=0)\n",
    "all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "# Calculate AUC and F1 score\n",
    "auc = roc_auc_score(all_targets.cpu().numpy(), all_predictions.cpu().numpy())\n",
    "f1 = f1_score(all_targets.cpu().numpy(), all_predictions.cpu().numpy(), average='weighted')\n",
    "\n",
    "# Print the AUC and F1 score\n",
    "print(f\"AUC: {auc:.4f}, F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rnn_dataset(dataset, lookback, test=False):\n",
    "    # Initialize empty lists to store the dataset components\n",
    "    all_features = []\n",
    "    all_targets = []\n",
    "    features_columns = ['creatinine', 'urine', 'measuredat', 'temp', 'heart_rate', 'systolic_ABP', 'mean_ABP', 'dystolic_ABP', 'resp_rate', 'glucose', 'hema', 'calcium', 'kalium', 'ox_sat', 'thrombo', 'bilirubine', 'leukocyten', 'hematocryt', 'lactate', 'sodium', 'ph']\n",
    "    temporal_columns = ['creatinine_change', 'urine_change', 'temp_change', 'heart_rate_change', 'systolic_ABP_change', 'mean_ABP_change', 'dystolic_ABP_change', 'resp_rate_change', 'glucose_change', 'hema_change', 'calcium_change', 'kalium_change', 'ox_sat_change', 'thrombo_change', 'bilirubine_change', 'leukocyten_change', 'hematocryt_change', 'lactate_change', 'sodium_change', 'ph_change']\n",
    "    extra_features = ['has_sepsis', 'has_ventilation', 'nsaid_taken', 'vassopressor_taken', 'acei_taken', 'arb_taken', 'cardiac_surgery', 'traumatology', 'vascular_surgery', 'gastroenterology_surgery', 'lungs_oncology_surgery', 'oncology_surgery', 'neuro_surgery', 'gender_Man', 'gender_Vrouw', 'agegroup', 'weightgroup', 'heightgroup']\n",
    "    threshold = 0.3\n",
    "\n",
    "    # Iterate over admission IDs\n",
    "    for admission_id in dataset['admissionid'].unique():\n",
    "        # Get the sample for the current admission ID\n",
    "        sample_patient = dataset[dataset['admissionid'] == admission_id].copy()\n",
    "        counter = 0\n",
    "        for i in range(len(sample_patient['AKI_12hours'])-lookback):\n",
    "            if counter >= 15:\n",
    "                break\n",
    "            feature = sample_patient[features_columns + extra_features].values[i:i+lookback]\n",
    "            target = sample_patient['AKI_12hours'].values[i+1:i+lookback+1]\n",
    "            \n",
    "            ratio = target.sum() / len(target)\n",
    "            # Check if the ratio is within the threshold range\n",
    "            if not test and threshold <= ratio <= 1 - threshold:\n",
    "                # Append the features and the target to the lists\n",
    "                all_features.append(feature)\n",
    "                all_targets.append(target)\n",
    "            if test:\n",
    "                all_features.append(feature)\n",
    "                all_targets.append(target)\n",
    "            counter += 1\n",
    "\n",
    "    # Convert the lists to tensors\n",
    "    all_features_tensor = torch.tensor(all_features, dtype=torch.float32)\n",
    "    all_targets_tensor = torch.tensor(all_targets, dtype=torch.float32)\n",
    " \n",
    "        # Print the shapes of the tensors\n",
    "    print(\"All targets Tensor Shape:\", all_targets_tensor.shape)\n",
    "    print(\"All Features Tensor Shape:\", all_features_tensor.shape)\n",
    "\n",
    "    return all_features_tensor, all_targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dheer\\AppData\\Local\\Temp\\ipykernel_29808\\1373349791.py:33: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  all_features_tensor = torch.tensor(all_features, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All targets Tensor Shape: torch.Size([1821, 10])\n",
      "All Features Tensor Shape: torch.Size([1821, 10, 39])\n",
      "All targets Tensor Shape: torch.Size([4323, 10])\n",
      "All Features Tensor Shape: torch.Size([4323, 10, 39])\n"
     ]
    }
   ],
   "source": [
    "lstm_train_data = make_rnn_dataset(encoded_dataset, 10)\n",
    "lstm_test_data = make_rnn_dataset(encoded_dataset_test, 10, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AKIModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        if bidirectional:\n",
    "            hidden_size *= 2\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, sequence, features)\n",
    "        output, _ = self.lstm(x)\n",
    "        # output shape: (batch, sequence, hidden_size)\n",
    "        output = self.linear(output)\n",
    "        # output shape: (batch, sequence, output_size)\n",
    "        output = torch.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 39\n",
    "hidden_size = 50\n",
    "num_layers = 4\n",
    "output_size = 1\n",
    "\n",
    "lstm_model = AKIModel(input_size, hidden_size, num_layers, output_size, bidirectional=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.utils.data as data\n",
    "# # load the model\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# lstm_model.load_state_dict(torch.load('models/lstm_model_1h'))\n",
    "# lstm_model.to(device)\n",
    "# test_loader = data.DataLoader(data.TensorDataset(lstm_test_data[0], lstm_test_data[1]), shuffle=False, batch_size=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Vrije\\DL2\\DL2\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss 0.1003, test loss 0.0902\n",
      "Epoch 5: train loss 0.0861, test loss 0.0910\n",
      "Early stopping triggered. No improvement in validation loss for 5 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Early stopping\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "optimizer = AdamW(lstm_model.parameters(), lr=learning_rate)\n",
    "loss_fn = F.mse_loss\n",
    "loader = data.DataLoader(data.TensorDataset(lstm_train_data[0], lstm_train_data[1]), shuffle=True, batch_size=8, pin_memory=True)\n",
    "test_loader = data.DataLoader(data.TensorDataset(lstm_test_data[0], lstm_test_data[1]), shuffle=False, batch_size=8, pin_memory=True)\n",
    "lstm_model.to(device)\n",
    "\n",
    "n_epochs = 30\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # Number of epochs to wait for improvement\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    lstm_model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        y_pred = lstm_model(X_batch)\n",
    "        y_pred = y_pred.squeeze()\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "    train_loss /= len(loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation\n",
    "    lstm_model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for X_val, y_val in test_loader:\n",
    "            X_val = X_val.to(device)\n",
    "            y_val = y_val.to(device)\n",
    "            y_pred = lstm_model(X_val)\n",
    "            y_pred = y_pred.squeeze()\n",
    "            loss = loss_fn(y_pred, y_val)\n",
    "            val_loss += loss.item() * X_val.size(0)\n",
    "        val_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(val_loss)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(\"Epoch %d: train loss %.4f, test loss %.4f\" % (epoch, train_loss, val_loss))\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping triggered. No improvement in validation loss for %d epochs.\" % patience)\n",
    "            break\n",
    "\n",
    "# Plot the training and test loss curves\n",
    "plt.plot(range(len(train_losses)), train_losses, label='Train Loss')\n",
    "plt.plot(range(0, len(test_losses) * 5, 5), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5000, F1 Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "lstm_all_targets = []\n",
    "lstm_all_predictions = []\n",
    "\n",
    "for batch_idx, batch in enumerate(test_loader):\n",
    "    lstm_model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_val, y_val = batch\n",
    "        X_val = X_val.to(device)\n",
    "        y_val = y_val.to(device)\n",
    "        y_pred = lstm_model(X_val)\n",
    "        y_pred = y_pred.squeeze()\n",
    "\n",
    "    # Append predictions and targets to lists\n",
    "    lstm_all_predictions.append(y_pred)\n",
    "    lstm_all_targets.append(y_val)\n",
    "\n",
    "# Concatenate the predictions and targets tensors\n",
    "lstm_all_predictions = torch.cat(lstm_all_predictions, dim=0)\n",
    "lstm_all_targets = torch.cat(lstm_all_targets, dim=0)\n",
    "\n",
    "# Flatten the predictions and targets\n",
    "y_true = lstm_all_targets.cpu().numpy().flatten()\n",
    "y_pred = lstm_all_predictions.cpu().numpy().flatten()\n",
    "threshold = 0.5  # Set the threshold for classification\n",
    "y_pred_binary = np.where(y_pred >= threshold, 1, 0)\n",
    "\n",
    "# Calculate AUC and F1 score\n",
    "auc = roc_auc_score(y_true, y_pred_binary)\n",
    "f1 = f1_score(y_true, y_pred_binary)\n",
    "\n",
    "# Print the AUC and F1 score\n",
    "print(f\"AUC: {auc:.4f}, F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8659, F1 Score: 0.8694\n",
      "Confusion Matrix:\n",
      "[[733 109]\n",
      " [126 782]]\n",
      "Precision: 0.8777\n",
      "Recall: 0.8612\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "y_true = lstm_all_targets.cpu().numpy()\n",
    "threshold = 0.5  # Set the threshold for classification\n",
    "y_pred_binary = np.where(lstm_all_predictions.cpu() >= threshold, 1, 0)\n",
    "# Convert y_true to int\n",
    "y_true = y_true.astype(int)\n",
    "# flatten y_true and y_pred_binary\n",
    "y_true = y_true.flatten()\n",
    "y_pred_binary = y_pred_binary.flatten()\n",
    "confusion_mat = confusion_matrix(y_true, y_pred_binary)\n",
    "precision = precision_score(y_true, y_pred_binary)\n",
    "recall = recall_score(y_true, y_pred_binary)\n",
    "\n",
    "# Print the AUC, F1 score, confusion matrix, precision, and recall\n",
    "print(f\"AUC: {auc:.4f}, F1 Score: {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"models/bilstm_model_12h\"\n",
    "torch.save(lstm_model.state_dict(), save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
