{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set transformer cache to \"./.transformer_cache\"\n",
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = './cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerModel, TimeSeriesTransformerForPrediction\n",
    "from transformers import AdamW\n",
    "from sklearn.metrics import roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admissionid</th>\n",
       "      <th>hour</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>urine</th>\n",
       "      <th>measuredat</th>\n",
       "      <th>baseline_creatinine</th>\n",
       "      <th>temp</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>systolic_ABP</th>\n",
       "      <th>mean_ABP</th>\n",
       "      <th>...</th>\n",
       "      <th>hematocryt_change</th>\n",
       "      <th>lactate_change</th>\n",
       "      <th>sodium_change</th>\n",
       "      <th>ph_change</th>\n",
       "      <th>stage_6hours</th>\n",
       "      <th>AKI_6hours</th>\n",
       "      <th>icu_days</th>\n",
       "      <th>stage_3hours</th>\n",
       "      <th>AKI</th>\n",
       "      <th>AKI_3hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>10800000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>32.966667</td>\n",
       "      <td>79.333333</td>\n",
       "      <td>137.666667</td>\n",
       "      <td>98.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>21600000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>34.240000</td>\n",
       "      <td>70.333333</td>\n",
       "      <td>122.666667</td>\n",
       "      <td>85.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>103.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>32400000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>34.883333</td>\n",
       "      <td>79.250000</td>\n",
       "      <td>141.250000</td>\n",
       "      <td>99.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>94.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>43200000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>33.187500</td>\n",
       "      <td>67.750000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>94.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>54000000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>33.283333</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   admissionid  hour  creatinine  urine  measuredat  baseline_creatinine  \\\n",
       "0            9     0       103.0  360.0    10800000                 94.0   \n",
       "1            9     1       103.0  185.0    21600000                 94.0   \n",
       "2            9     2       103.0  220.0    32400000                 94.0   \n",
       "3            9     3        94.0  145.0    43200000                 94.0   \n",
       "4            9     4        94.0  115.0    54000000                 94.0   \n",
       "\n",
       "        temp  heart_rate  systolic_ABP   mean_ABP  ...  hematocryt_change  \\\n",
       "0  32.966667   79.333333    137.666667  98.333333  ...           0.000000   \n",
       "1  34.240000   70.333333    122.666667  85.333333  ...          -0.002500   \n",
       "2  34.883333   79.250000    141.250000  99.250000  ...          -0.010000   \n",
       "3  33.187500   67.750000    126.000000  83.000000  ...           0.018333   \n",
       "4  33.283333   70.000000    133.000000  91.000000  ...          -0.023333   \n",
       "\n",
       "   lactate_change  sodium_change  ph_change  stage_6hours  AKI_6hours  \\\n",
       "0             0.0       0.000000       0.00           0.0           0   \n",
       "1             0.0      -0.500000       0.05           0.0           0   \n",
       "2             0.0       2.083333      -0.07           0.0           0   \n",
       "3             0.0      -1.000000       0.01           0.0           0   \n",
       "4             0.0      -0.833333       0.00           0.0           0   \n",
       "\n",
       "   icu_days  stage_3hours  AKI  AKI_3hours  \n",
       "0     0.000           0.0    0         0.0  \n",
       "1     0.125           0.0    0         0.0  \n",
       "2     0.250           0.0    0         0.0  \n",
       "3     0.375           0.0    0         0.0  \n",
       "4     0.500           0.0    0         0.0  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train_data_3h.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test_data_3h.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the categorical features from the dataframe\n",
    "categorical_features = df.select_dtypes(include=['object', 'bool'])\n",
    "\n",
    "# Apply label encoder to the categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_categorical_features = categorical_features.apply(label_encoder.fit_transform)\n",
    "\n",
    "# Combine the encoded categorical features with the numerical features\n",
    "numerical_features = df.select_dtypes(include=['float', 'int'])\n",
    "encoded_dataset = pd.concat([numerical_features, encoded_categorical_features], axis=1)\n",
    "\n",
    "# Apply label encoder to test\n",
    "categorical_features_test = test_df.select_dtypes(include=['object', 'bool'])\n",
    "encoded_categorical_features_test = categorical_features_test.apply(label_encoder.fit_transform)\n",
    "numerical_features_test = test_df.select_dtypes(include=['float', 'int'])\n",
    "encoded_dataset_test = pd.concat([numerical_features_test, encoded_categorical_features_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Length of AKI-6hours: 102.77642206564701\n",
      "Average Count of 0s: 53.44526550953772\n",
      "Average Count of 1s: 49.3311565561093\n",
      "Minimum Length of AKI-6hours: 2\n",
      "Maximum Length of AKI-6hours: 1823\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty lists to store the results\n",
    "average_length = []\n",
    "average_count_0 = []\n",
    "average_count_1 = []\n",
    "\n",
    "# Iterate through the encoded_dataset\n",
    "for admissionid, admissionid_df in encoded_dataset.groupby('admissionid'):\n",
    "    # print(admissionid)\n",
    "    # print(admissionid_df['AKI_6hours'].values)\n",
    "    \n",
    "    # Calculate the average length of AKI-6hours\n",
    "    length = len(admissionid_df['AKI_3hours'].values)\n",
    "    average_length.append(length)\n",
    "    \n",
    "    # Calculate the average count of 0s and 1s\n",
    "    count_0 = np.count_nonzero(admissionid_df['AKI_3hours'].values == 0)\n",
    "    count_1 = np.count_nonzero(admissionid_df['AKI_3hours'].values == 1)\n",
    "    average_count_0.append(count_0)\n",
    "    average_count_1.append(count_1)\n",
    "    \n",
    "# Calculate the overall averages\n",
    "overall_average_length = np.mean(average_length)\n",
    "overall_average_count_0 = np.mean(average_count_0)\n",
    "overall_average_count_1 = np.mean(average_count_1)\n",
    "\n",
    "# Print the results\n",
    "print(\"Average Length of AKI-6hours:\", overall_average_length)\n",
    "print(\"Average Count of 0s:\", overall_average_count_0)\n",
    "print(\"Average Count of 1s:\", overall_average_count_1)\n",
    "print(\"Minimum Length of AKI-6hours:\", np.min(average_length))\n",
    "print(\"Maximum Length of AKI-6hours:\", np.max(average_length))\n",
    "\n",
    "# Use these counts to determine the context length and prediction length\n",
    "# 24 context length, 8 prediction length, 4 lag sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_dataset(dataset, context_length, prediction_length, lag_length):\n",
    "    # Initialize empty lists to store the dataset components\n",
    "    all_past_values = []\n",
    "    all_future_values = []\n",
    "    all_past_time_features = []\n",
    "    all_future_time_features = []\n",
    "    all_past_values_mask = []\n",
    "\n",
    "    features_columns = ['creatinine', 'urine', 'measuredat', 'temp', 'heart_rate', 'systolic_ABP', 'mean_ABP', 'dystolic_ABP', 'resp_rate', 'glucose', 'hema', 'calcium', 'kalium', 'ox_sat', 'thrombo', 'bilirubine', 'leukocyten', 'hematocryt', 'lactate', 'sodium', 'ph']\n",
    "    temporal_columns = ['creatinine_change', 'urine_change', 'temp_change', 'heart_rate_change', 'systolic_ABP_change', 'mean_ABP_change', 'dystolic_ABP_change', 'resp_rate_change', 'glucose_change', 'hema_change', 'calcium_change', 'kalium_change', 'ox_sat_change', 'thrombo_change', 'bilirubine_change', 'leukocyten_change', 'hematocryt_change', 'lactate_change', 'sodium_change', 'ph_change']\n",
    "    extra_features = ['has_sepsis', 'has_ventilation', 'nsaid_taken', 'vassopressor_taken', 'acei_taken', 'arb_taken', 'cardiac_surgery', 'traumatology', 'vascular_surgery', 'gastroenterology_surgery', 'lungs_oncology_surgery', 'oncology_surgery', 'neuro_surgery', 'gender_Man', 'gender_Vrouw', 'agegroup', 'weightgroup', 'heightgroup']\n",
    "\n",
    "\n",
    "    # Iterate over admission IDs\n",
    "    for admission_id in dataset['admissionid'].unique():\n",
    "        # Get the sample for the current admission ID\n",
    "        sample_patient = dataset[dataset['admissionid'] == admission_id].copy()\n",
    "\n",
    "        # Check if the sample patient has enough AKI_6hours values\n",
    "        if len(sample_patient['AKI_3hours']) >= context_length + lag_length + prediction_length:\n",
    "            # Split the dataframe into the required components\n",
    "            past_values = sample_patient['AKI_3hours'].values[:context_length + lag_length]\n",
    "            future_values = sample_patient['AKI_3hours'].values[context_length + lag_length:context_length + lag_length + prediction_length]\n",
    "            sample_patient.drop(columns=['admissionid', 'patientid', 'admissionyeargroup', 'comparison_result', 'stage_6hours', 'AKI_6hours', 'stage_3hours', 'AKI', 'AKI_3hours'], inplace=True)\n",
    "            past_time_features = sample_patient[features_columns + extra_features].values[:context_length + lag_length]\n",
    "            future_time_features = sample_patient[features_columns + extra_features].values[context_length + lag_length:context_length + lag_length + prediction_length]\n",
    "            past_values_mask = np.ones(context_length)\n",
    "            \n",
    "            # Append the components to the respective lists\n",
    "            all_past_values.append(past_values)\n",
    "            all_future_values.append(future_values)\n",
    "            all_past_time_features.append(past_time_features)\n",
    "            all_future_time_features.append(future_time_features)\n",
    "            all_past_values_mask.append(past_values_mask)\n",
    "\n",
    "    # Convert the lists to tensors\n",
    "    all_past_values_tensor = torch.tensor(all_past_values, dtype=torch.float32)\n",
    "    all_future_values_tensor = torch.tensor(all_future_values, dtype=torch.float32)\n",
    "    all_past_time_features_tensor = torch.tensor(all_past_time_features, dtype=torch.float32)\n",
    "    all_future_time_features_tensor = torch.tensor(all_future_time_features, dtype=torch.float32)\n",
    "    all_past_values_mask_tensor = torch.tensor(all_past_values_mask, dtype=torch.float32)\n",
    "\n",
    "        # Print the shapes of the tensors\n",
    "    print(\"All Past Values Tensor Shape:\", all_past_values_tensor.shape)\n",
    "    print(\"All Future Values Tensor Shape:\", all_future_values_tensor.shape)\n",
    "    print(\"All Past Time Features Tensor Shape:\", all_past_time_features_tensor.shape)\n",
    "    print(\"All Future Time Features Tensor Shape:\", all_future_time_features_tensor.shape)\n",
    "\n",
    "    return {\"past_values\": all_past_values_tensor, \"future_values\":  all_future_values_tensor, \"past_features\": all_past_time_features_tensor, \"future_features\": all_future_time_features_tensor, \"past_values_mask\": all_past_values_mask_tensor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_columns = ['creatinine', 'urine', 'measuredat', 'temp', 'heart_rate', 'systolic_ABP', 'mean_ABP', 'dystolic_ABP', 'resp_rate', 'glucose', 'hema', 'calcium', 'kalium', 'ox_sat', 'thrombo', 'bilirubine', 'leukocyten', 'hematocryt', 'lactate', 'sodium', 'ph']\n",
    "temporal_columns = ['creatinine_change', 'urine_change', 'temp_change', 'heart_rate_change', 'systolic_ABP_change', 'mean_ABP_change', 'dystolic_ABP_change', 'resp_rate_change', 'glucose_change', 'hema_change', 'calcium_change', 'kalium_change', 'ox_sat_change', 'thrombo_change', 'bilirubine_change', 'leukocyten_change', 'hematocryt_change', 'lactate_change', 'sodium_change', 'ph_change']\n",
    "extra_features = ['has_sepsis', 'has_ventilation', 'nsaid_taken', 'vassopressor_taken', 'acei_taken', 'arb_taken', 'cardiac_surgery', 'traumatology', 'vascular_surgery', 'gastroenterology_surgery', 'lungs_oncology_surgery', 'oncology_surgery', 'neuro_surgery', 'gender_Man', 'gender_Vrouw', 'agegroup', 'weightgroup', 'heightgroup']\n",
    "len(features_columns + extra_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Past Values Tensor Shape: torch.Size([2300, 70])\n",
      "All Future Values Tensor Shape: torch.Size([2300, 12])\n",
      "All Past Time Features Tensor Shape: torch.Size([2300, 70, 39])\n",
      "All Future Time Features Tensor Shape: torch.Size([2300, 12, 39])\n",
      "All Past Values Tensor Shape: torch.Size([188, 70])\n",
      "All Future Values Tensor Shape: torch.Size([188, 12])\n",
      "All Past Time Features Tensor Shape: torch.Size([188, 70, 39])\n",
      "All Future Time Features Tensor Shape: torch.Size([188, 12, 39])\n"
     ]
    }
   ],
   "source": [
    "context_length = 64\n",
    "prediction_length = 12\n",
    "lag_length = 6\n",
    "train_data = make_train_dataset(encoded_dataset, context_length, prediction_length, lag_length)\n",
    "test_data = make_train_dataset(encoded_dataset_test, context_length, prediction_length, lag_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorDataset\n",
    "train_dataset = TensorDataset(train_data[\"past_values\"], train_data[\"future_values\"], train_data[\"past_features\"], train_data[\"future_features\"], train_data[\"past_values_mask\"])\n",
    "test_dataset = TensorDataset(test_data[\"past_values\"], test_data[\"future_values\"], test_data[\"past_features\"], test_data[\"future_features\"], test_data[\"past_values_mask\"])\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesTransformerConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"cardinality\": [\n",
      "    0\n",
      "  ],\n",
      "  \"context_length\": 64,\n",
      "  \"d_model\": 128,\n",
      "  \"decoder_attention_heads\": 4,\n",
      "  \"decoder_ffn_dim\": 512,\n",
      "  \"decoder_layerdrop\": 0.1,\n",
      "  \"decoder_layers\": 4,\n",
      "  \"distribution_output\": \"student_t\",\n",
      "  \"dropout\": 0.1,\n",
      "  \"embedding_dimension\": [\n",
      "    0\n",
      "  ],\n",
      "  \"encoder_attention_heads\": 2,\n",
      "  \"encoder_ffn_dim\": 512,\n",
      "  \"encoder_layerdrop\": 0.1,\n",
      "  \"encoder_layers\": 4,\n",
      "  \"feature_size\": 45,\n",
      "  \"init_std\": 0.02,\n",
      "  \"input_size\": 1,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"lags_sequence\": [\n",
      "    1,\n",
      "    2,\n",
      "    4,\n",
      "    6\n",
      "  ],\n",
      "  \"loss\": \"nll\",\n",
      "  \"model_type\": \"time_series_transformer\",\n",
      "  \"num_dynamic_real_features\": 0,\n",
      "  \"num_parallel_samples\": 100,\n",
      "  \"num_static_categorical_features\": 0,\n",
      "  \"num_static_real_features\": 0,\n",
      "  \"num_time_features\": 39,\n",
      "  \"prediction_length\": 12,\n",
      "  \"scaling\": \"mean\",\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"use_cache\": true\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initializing a default Time Series Transformer configuration\n",
    "configuration = TimeSeriesTransformerConfig(context_length=context_length, lags_sequence=[1, 2, 4, 6], prediction_length=prediction_length, num_time_features=39,\n",
    "                                            encoder_layers=4, decoder_layers=4, encoder_attention_heads=2, decoder_attention_heads=4,\n",
    "                                            d_model=128, encoder_ffn_dim=512, decoder_ffn_dim=512,\n",
    "\n",
    ")\n",
    "\n",
    "# Randomly initializing a model (with random weights) from the configuration\n",
    "model = TimeSeriesTransformerForPrediction(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "print(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 1883267\n",
      "Total trainable parameters: 1863811\n"
     ]
    }
   ],
   "source": [
    "# print count of parameters in the model\n",
    "print(\"Number of parameters:\", model.num_parameters())\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total trainable parameters:\", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Vrije\\DL2\\DL2\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: -9.9803\n",
      "Epoch 2/10, Loss: -10.0377\n",
      "Epoch 3/10, Loss: -10.0308\n",
      "Epoch 4/10, Loss: -10.0581\n",
      "Epoch 5/10, Loss: -10.0659\n",
      "Epoch 6/10, Loss: -10.0678\n",
      "Epoch 7/10, Loss: -10.0046\n",
      "Epoch 8/10, Loss: -9.9709\n",
      "Epoch 9/10, Loss: -10.0010\n",
      "Epoch 10/10, Loss: -10.0246\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    total_batches = len(train_dataloader)\n",
    "\n",
    "    # Iterate over the batches\n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        past_values_batch, future_values_batch, past_time_features_batch, future_time_features_batch, past_values_mask_batch = batch\n",
    "        \n",
    "        # # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            past_values=past_values_batch,\n",
    "            past_time_features=past_time_features_batch,\n",
    "            past_observed_mask=past_values_mask_batch,\n",
    "            future_values=future_values_batch,\n",
    "            future_time_features=future_time_features_batch,\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate the loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Print batch loss\n",
    "        # print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx+1}/{total_batches}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Print the average loss for the epoch\n",
    "    average_loss = running_loss / total_batches\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {average_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8075, F1 Score: 0.7616\n"
     ]
    }
   ],
   "source": [
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for batch_idx, batch in enumerate(test_dataloader):\n",
    "    past_values_batch, future_values_batch, past_time_features_batch, future_time_features_batch, past_values_mask_batch = batch\n",
    "    outputs = model.generate(\n",
    "        past_values=past_values_batch,\n",
    "        past_time_features=past_time_features_batch,\n",
    "        past_observed_mask=past_values_mask_batch,\n",
    "        future_time_features=future_time_features_batch,\n",
    "    )\n",
    "\n",
    "    mean_prediction = outputs.sequences.mean(dim=1)\n",
    "\n",
    "    # Round the predictions to nearest integer\n",
    "    predictions = torch.round(mean_prediction)\n",
    "    targets = future_values_batch\n",
    "\n",
    "    # Append predictions and targets to lists\n",
    "    all_predictions.append(predictions)\n",
    "    all_targets.append(targets)\n",
    "\n",
    "# Concatenate the predictions and targets tensors\n",
    "all_predictions = torch.cat(all_predictions, dim=0)\n",
    "all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "# Calculate AUC and F1 score\n",
    "auc = roc_auc_score(all_targets.cpu().numpy(), all_predictions.cpu().numpy())\n",
    "f1 = f1_score(all_targets.cpu().numpy(), all_predictions.cpu().numpy(), average='weighted')\n",
    "\n",
    "# Print the AUC and F1 score\n",
    "print(f\"AUC: {auc:.4f}, F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying without temporal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Past Values Tensor Shape: torch.Size([2300, 70])\n",
      "All Future Values Tensor Shape: torch.Size([2300, 12])\n",
      "All Past Time Features Tensor Shape: torch.Size([2300, 70, 41])\n",
      "All Future Time Features Tensor Shape: torch.Size([2300, 12, 41])\n",
      "All Past Values Tensor Shape: torch.Size([188, 70])\n",
      "All Future Values Tensor Shape: torch.Size([188, 12])\n",
      "All Past Time Features Tensor Shape: torch.Size([188, 70, 41])\n",
      "All Future Time Features Tensor Shape: torch.Size([188, 12, 41])\n"
     ]
    }
   ],
   "source": [
    "train_data_noExtra = make_train_dataset(encoded_dataset, context_length, prediction_length, lag_length)\n",
    "test_data_noExtra = make_train_dataset(encoded_dataset_test, context_length, prediction_length, lag_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorDataset\n",
    "train_dataset_noExtra = TensorDataset(train_data_noExtra[\"past_values\"], train_data_noExtra[\"future_values\"], train_data_noExtra[\"past_features\"], train_data_noExtra[\"future_features\"], train_data_noExtra[\"past_values_mask\"])\n",
    "test_dataset_noExtra = TensorDataset(test_data_noExtra[\"past_values\"], test_data_noExtra[\"future_values\"], test_data_noExtra[\"past_features\"], test_data_noExtra[\"future_features\"], test_data_noExtra[\"past_values_mask\"])\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 16\n",
    "train_dataloader_noExtra = DataLoader(train_dataset_noExtra, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader_noExtra = DataLoader(test_dataset_noExtra, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesTransformerConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"cardinality\": [\n",
      "    0\n",
      "  ],\n",
      "  \"context_length\": 64,\n",
      "  \"d_model\": 128,\n",
      "  \"decoder_attention_heads\": 4,\n",
      "  \"decoder_ffn_dim\": 512,\n",
      "  \"decoder_layerdrop\": 0.1,\n",
      "  \"decoder_layers\": 4,\n",
      "  \"distribution_output\": \"student_t\",\n",
      "  \"dropout\": 0.1,\n",
      "  \"embedding_dimension\": [\n",
      "    0\n",
      "  ],\n",
      "  \"encoder_attention_heads\": 2,\n",
      "  \"encoder_ffn_dim\": 512,\n",
      "  \"encoder_layerdrop\": 0.1,\n",
      "  \"encoder_layers\": 4,\n",
      "  \"feature_size\": 47,\n",
      "  \"init_std\": 0.02,\n",
      "  \"input_size\": 1,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"lags_sequence\": [\n",
      "    1,\n",
      "    2,\n",
      "    4,\n",
      "    6\n",
      "  ],\n",
      "  \"loss\": \"nll\",\n",
      "  \"model_type\": \"time_series_transformer\",\n",
      "  \"num_dynamic_real_features\": 0,\n",
      "  \"num_parallel_samples\": 100,\n",
      "  \"num_static_categorical_features\": 0,\n",
      "  \"num_static_real_features\": 0,\n",
      "  \"num_time_features\": 41,\n",
      "  \"prediction_length\": 12,\n",
      "  \"scaling\": \"mean\",\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"use_cache\": true\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initializing a default Time Series Transformer configuration\n",
    "configuration2 = TimeSeriesTransformerConfig(context_length=context_length, lags_sequence=[1, 2, 4, 6], prediction_length=prediction_length, num_time_features=41,\n",
    "                                            encoder_layers=4, decoder_layers=4, encoder_attention_heads=2, decoder_attention_heads=4,\n",
    "                                            d_model=128, encoder_ffn_dim=512, decoder_ffn_dim=512,\n",
    "\n",
    ")\n",
    "\n",
    "# Randomly initializing a model (with random weights) from the configuration\n",
    "model2 = TimeSeriesTransformerForPrediction(configuration2)\n",
    "\n",
    "# Accessing the model configuration\n",
    "# configuration = model.config\n",
    "print(configuration2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Vrije\\DL2\\DL2\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: -9.9325\n",
      "Epoch 2/10, Loss: -10.0055\n",
      "Epoch 3/10, Loss: -10.0194\n",
      "Epoch 4/10, Loss: -10.0422\n",
      "Epoch 5/10, Loss: -10.0353\n",
      "Epoch 6/10, Loss: -10.0474\n",
      "Epoch 7/10, Loss: -10.0382\n",
      "Epoch 8/10, Loss: -10.0501\n",
      "Epoch 9/10, Loss: -10.0505\n",
      "Epoch 10/10, Loss: -10.0564\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "optimizer = AdamW(model2.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    total_batches = len(train_dataloader_noExtra)\n",
    "\n",
    "    # Iterate over the batches\n",
    "    for batch_idx, batch in enumerate(train_dataloader_noExtra):\n",
    "        past_values_batch, future_values_batch, past_time_features_batch, future_time_features_batch, past_values_mask_batch = batch\n",
    "        \n",
    "        # # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model2(\n",
    "            past_values=past_values_batch,\n",
    "            past_time_features=past_time_features_batch,\n",
    "            past_observed_mask=past_values_mask_batch,\n",
    "            future_values=future_values_batch,\n",
    "            future_time_features=future_time_features_batch,\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate the loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Print batch loss\n",
    "        # print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx+1}/{total_batches}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Print the average loss for the epoch\n",
    "    average_loss = running_loss / total_batches\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {average_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.6717, F1 Score: 0.5103\n"
     ]
    }
   ],
   "source": [
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for batch_idx, batch in enumerate(test_dataloader_noExtra):\n",
    "    past_values_batch, future_values_batch, past_time_features_batch, future_time_features_batch, past_values_mask_batch = batch\n",
    "    outputs = model2.generate(\n",
    "        past_values=past_values_batch,\n",
    "        past_time_features=past_time_features_batch,\n",
    "        past_observed_mask=past_values_mask_batch,\n",
    "        future_time_features=future_time_features_batch,\n",
    "    )\n",
    "\n",
    "    mean_prediction = outputs.sequences.mean(dim=1)\n",
    "\n",
    "    # Round the predictions to nearest integer\n",
    "    predictions = torch.round(mean_prediction)\n",
    "    targets = future_values_batch\n",
    "\n",
    "    # Append predictions and targets to lists\n",
    "    all_predictions.append(predictions)\n",
    "    all_targets.append(targets)\n",
    "\n",
    "# Concatenate the predictions and targets tensors\n",
    "all_predictions = torch.cat(all_predictions, dim=0)\n",
    "all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "# Calculate AUC and F1 score\n",
    "auc = roc_auc_score(all_targets.cpu().numpy(), all_predictions.cpu().numpy())\n",
    "f1 = f1_score(all_targets.cpu().numpy(), all_predictions.cpu().numpy(), average='weighted')\n",
    "\n",
    "# Print the AUC and F1 score\n",
    "print(f\"AUC: {auc:.4f}, F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting Autoformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoformerConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"autocorrelation_factor\": 3,\n",
      "  \"cardinality\": [\n",
      "    0\n",
      "  ],\n",
      "  \"context_length\": 64,\n",
      "  \"d_model\": 128,\n",
      "  \"decoder_attention_heads\": 4,\n",
      "  \"decoder_ffn_dim\": 512,\n",
      "  \"decoder_layerdrop\": 0.1,\n",
      "  \"decoder_layers\": 4,\n",
      "  \"distribution_output\": \"student_t\",\n",
      "  \"dropout\": 0.1,\n",
      "  \"embedding_dimension\": [\n",
      "    0\n",
      "  ],\n",
      "  \"encoder_attention_heads\": 2,\n",
      "  \"encoder_ffn_dim\": 512,\n",
      "  \"encoder_layerdrop\": 0.1,\n",
      "  \"encoder_layers\": 4,\n",
      "  \"feature_size\": 66,\n",
      "  \"init_std\": 0.02,\n",
      "  \"input_size\": 1,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label_length\": 10,\n",
      "  \"lags_sequence\": [\n",
      "    1,\n",
      "    2,\n",
      "    4,\n",
      "    6\n",
      "  ],\n",
      "  \"loss\": \"nll\",\n",
      "  \"model_type\": \"autoformer\",\n",
      "  \"moving_average\": 25,\n",
      "  \"num_dynamic_real_features\": 0,\n",
      "  \"num_parallel_samples\": 100,\n",
      "  \"num_static_categorical_features\": 0,\n",
      "  \"num_static_real_features\": 0,\n",
      "  \"num_time_features\": 60,\n",
      "  \"prediction_length\": 12,\n",
      "  \"scaling\": true,\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"use_cache\": true\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoformerConfig, AutoformerForPrediction\n",
    "\n",
    "# Initializing a default Time Series Transformer configuration\n",
    "configuration = AutoformerConfig(context_length=context_length, lags_sequence=[1, 2, 4, 6], prediction_length=prediction_length, num_time_features=60,\n",
    "                                            encoder_layers=4, decoder_layers=4, encoder_attention_heads=2, decoder_attention_heads=4,\n",
    "                                            d_model=128, encoder_ffn_dim=512, decoder_ffn_dim=512,\n",
    "\n",
    ")\n",
    "\n",
    "# Randomly initializing a model (with random weights) from the configuration\n",
    "af_model = AutoformerForPrediction(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = af_model.config\n",
    "print(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Vrije\\DL2\\DL2\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 5.2349\n",
      "Epoch 2/10, Loss: 4.9259\n",
      "Epoch 3/10, Loss: 23.1917\n",
      "Epoch 4/10, Loss: 67.1245\n",
      "Epoch 5/10, Loss: 67.9182\n",
      "Epoch 6/10, Loss: 68.1288\n",
      "Epoch 7/10, Loss: 67.1217\n",
      "Epoch 8/10, Loss: 65.2447\n",
      "Epoch 9/10, Loss: 69.2943\n",
      "Epoch 10/10, Loss: 65.1153\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "optimizer = AdamW(af_model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    total_batches = len(train_dataloader)\n",
    "\n",
    "    # Iterate over the batches\n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        past_values_batch, future_values_batch, past_time_features_batch, future_time_features_batch, past_values_mask_batch = batch\n",
    "        \n",
    "        # # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = af_model(\n",
    "            past_values=past_values_batch,\n",
    "            past_time_features=past_time_features_batch,\n",
    "            past_observed_mask=past_values_mask_batch,\n",
    "            future_values=future_values_batch,\n",
    "            future_time_features=future_time_features_batch,\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate the loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Print batch loss\n",
    "        # print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx+1}/{total_batches}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Print the average loss for the epoch\n",
    "    average_loss = running_loss / total_batches\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {average_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5000, F1 Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for batch_idx, batch in enumerate(test_dataloader):\n",
    "    past_values_batch, future_values_batch, past_time_features_batch, future_time_features_batch, past_values_mask_batch = batch\n",
    "    outputs = af_model.generate(\n",
    "        past_values=past_values_batch,\n",
    "        past_time_features=past_time_features_batch,\n",
    "        past_observed_mask=past_values_mask_batch,\n",
    "        future_time_features=future_time_features_batch,\n",
    "    )\n",
    "\n",
    "    mean_prediction = outputs.sequences.mean(dim=1)\n",
    "\n",
    "    # Round the predictions to nearest integer\n",
    "    predictions = torch.round(mean_prediction)\n",
    "    targets = future_values_batch\n",
    "\n",
    "    # Append predictions and targets to lists\n",
    "    all_predictions.append(predictions)\n",
    "    all_targets.append(targets)\n",
    "\n",
    "# Concatenate the predictions and targets tensors\n",
    "all_predictions = torch.cat(all_predictions, dim=0)\n",
    "all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "# Convert other predictions to 0 and 1\n",
    "all_predictions[all_predictions > 1] = 1\n",
    "all_predictions[all_predictions < 0] = 0\n",
    "\n",
    "# Calculate AUC and F1 score\n",
    "auc = roc_auc_score(all_targets.cpu().numpy(), all_predictions.cpu().numpy())\n",
    "f1 = f1_score(all_targets.cpu().numpy(), all_predictions.cpu().numpy(), average='weighted')\n",
    "\n",
    "# Print the AUC and F1 score\n",
    "print(f\"AUC: {auc:.4f}, F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rnn_dataset(dataset, lookback, test=False):\n",
    "    # Initialize empty lists to store the dataset components\n",
    "    all_features = []\n",
    "    all_targets = []\n",
    "    features_columns = ['creatinine', 'urine', 'measuredat', 'temp', 'heart_rate', 'systolic_ABP', 'mean_ABP', 'dystolic_ABP', 'resp_rate', 'glucose', 'hema', 'calcium', 'kalium', 'ox_sat', 'thrombo', 'bilirubine', 'leukocyten', 'hematocryt', 'lactate', 'sodium', 'ph']\n",
    "    temporal_columns = ['creatinine_change', 'urine_change', 'temp_change', 'heart_rate_change', 'systolic_ABP_change', 'mean_ABP_change', 'dystolic_ABP_change', 'resp_rate_change', 'glucose_change', 'hema_change', 'calcium_change', 'kalium_change', 'ox_sat_change', 'thrombo_change', 'bilirubine_change', 'leukocyten_change', 'hematocryt_change', 'lactate_change', 'sodium_change', 'ph_change']\n",
    "    extra_features = ['has_sepsis', 'has_ventilation', 'nsaid_taken', 'vassopressor_taken', 'acei_taken', 'arb_taken', 'cardiac_surgery', 'traumatology', 'vascular_surgery', 'gastroenterology_surgery', 'lungs_oncology_surgery', 'oncology_surgery', 'neuro_surgery', 'gender_Man', 'gender_Vrouw', 'agegroup', 'weightgroup', 'heightgroup']\n",
    "    threshold = 0.3\n",
    "\n",
    "    # Iterate over admission IDs\n",
    "    for admission_id in dataset['admissionid'].unique():\n",
    "        # Get the sample for the current admission ID\n",
    "        sample_patient = dataset[dataset['admissionid'] == admission_id].copy()\n",
    "        counter = 0\n",
    "        for i in range(len(sample_patient['AKI_6hours'])-lookback):\n",
    "            if counter >= 15:\n",
    "                break\n",
    "            feature = sample_patient[features_columns + extra_features].values[i:i+lookback]\n",
    "            target = sample_patient['AKI_6hours'].values[i+1:i+lookback+1]\n",
    "            \n",
    "            ratio = target.sum() / len(target)\n",
    "            # Check if the ratio is within the threshold range\n",
    "            if not test and threshold <= ratio <= 1 - threshold:\n",
    "                # Append the features and the target to the lists\n",
    "                all_features.append(feature)\n",
    "                all_targets.append(target)\n",
    "            if test:\n",
    "                all_features.append(feature)\n",
    "                all_targets.append(target)\n",
    "            counter += 1\n",
    "\n",
    "    # Convert the lists to tensors\n",
    "    all_features_tensor = torch.tensor(all_features, dtype=torch.float32)\n",
    "    all_targets_tensor = torch.tensor(all_targets, dtype=torch.float32)\n",
    " \n",
    "        # Print the shapes of the tensors\n",
    "    print(\"All targets Tensor Shape:\", all_targets_tensor.shape)\n",
    "    print(\"All Features Tensor Shape:\", all_features_tensor.shape)\n",
    "\n",
    "    return all_features_tensor, all_targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_columns = ['creatinine', 'urine', 'measuredat', 'temp', 'heart_rate', 'systolic_ABP', 'mean_ABP', 'dystolic_ABP', 'resp_rate', 'glucose', 'hema', 'calcium', 'kalium', 'ox_sat', 'thrombo', 'bilirubine', 'leukocyten', 'hematocryt', 'lactate', 'sodium', 'ph']\n",
    "extra_features = ['has_sepsis', 'has_ventilation', 'nsaid_taken', 'vassopressor_taken', 'acei_taken', 'arb_taken', 'cardiac_surgery', 'traumatology', 'vascular_surgery', 'gastroenterology_surgery', 'lungs_oncology_surgery', 'oncology_surgery', 'neuro_surgery', 'gender_Man', 'gender_Vrouw', 'agegroup', 'weightgroup', 'heightgroup']\n",
    "\n",
    "len(features_columns + extra_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5819"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of admissionids in the encoded_dataset\n",
    "len(encoded_dataset['admissionid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dheer\\AppData\\Local\\Temp\\ipykernel_29844\\711099617.py:33: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  all_features_tensor = torch.tensor(all_features, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All targets Tensor Shape: torch.Size([3437, 10])\n",
      "All Features Tensor Shape: torch.Size([3437, 10, 39])\n",
      "All targets Tensor Shape: torch.Size([28046, 10])\n",
      "All Features Tensor Shape: torch.Size([28046, 10, 39])\n"
     ]
    }
   ],
   "source": [
    "lstm_train_data = make_rnn_dataset(encoded_dataset, 10)\n",
    "lstm_test_data = make_rnn_dataset(encoded_dataset_test, 10, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AKIModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        if bidirectional:\n",
    "            hidden_size *= 2\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, sequence, features)\n",
    "        output, _ = self.lstm(x)\n",
    "        # output shape: (batch, sequence, hidden_size)\n",
    "        output = self.linear(output)\n",
    "        # output shape: (batch, sequence, output_size)\n",
    "        output = torch.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 39\n",
    "hidden_size = 50\n",
    "num_layers = 4\n",
    "output_size = 1\n",
    "\n",
    "lstm_model = AKIModel(input_size, hidden_size, num_layers, output_size, bidirectional=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.utils.data as data\n",
    "# # load the model\n",
    "# lstm_model.load_state_dict(torch.load('models/lstm_model_3h'))\n",
    "# test_loader = data.DataLoader(data.TensorDataset(lstm_test_data[0], lstm_test_data[1]), shuffle=False, batch_size=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Vrije\\DL2\\DL2\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss 0.1078, test loss 0.4095\n",
      "Epoch 5: train loss 0.0838, test loss 0.4095\n",
      "Epoch 10: train loss 0.0836, test loss 0.4095\n",
      "Epoch 15: train loss 0.0836, test loss 0.4095\n",
      "Epoch 20: train loss 0.0835, test loss 0.4095\n",
      "Epoch 25: train loss 0.0835, test loss 0.4095\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Early stopping\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "optimizer = AdamW(lstm_model.parameters(), lr=learning_rate)\n",
    "loss_fn = F.mse_loss\n",
    "loader = data.DataLoader(data.TensorDataset(lstm_train_data[0], lstm_train_data[1]), shuffle=True, batch_size=8, pin_memory=True)\n",
    "test_loader = data.DataLoader(data.TensorDataset(lstm_test_data[0], lstm_test_data[1]), shuffle=False, batch_size=8, pin_memory=True)\n",
    "lstm_model.to(device)\n",
    "\n",
    "n_epochs = 30\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # Number of epochs to wait for improvement\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    lstm_model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        y_pred = lstm_model(X_batch)\n",
    "        y_pred = y_pred.squeeze()\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "    train_loss /= len(loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation\n",
    "    lstm_model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for X_val, y_val in test_loader:\n",
    "            X_val = X_val.to(device)\n",
    "            y_val = y_val.to(device)\n",
    "            y_pred = lstm_model(X_val)\n",
    "            y_pred = y_pred.squeeze()\n",
    "            loss = loss_fn(y_pred, y_val)\n",
    "            val_loss += loss.item() * X_val.size(0)\n",
    "        val_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(val_loss)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(\"Epoch %d: train loss %.4f, test loss %.4f\" % (epoch, train_loss, val_loss))\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping triggered. No improvement in validation loss for %d epochs.\" % patience)\n",
    "            break\n",
    "\n",
    "# Plot the training and test loss curves\n",
    "plt.plot(range(len(train_losses)), train_losses, label='Train Loss')\n",
    "plt.plot(range(0, len(test_losses) * 5, 5), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5200, F1 Score: 0.3867\n"
     ]
    }
   ],
   "source": [
    "lstm_all_targets = []\n",
    "lstm_all_predictions = []\n",
    "\n",
    "for batch_idx, batch in enumerate(test_loader):\n",
    "    lstm_model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_val, y_val = batch\n",
    "        X_val = X_val.to(device)\n",
    "        y_val = y_val.to(device)\n",
    "        y_pred = lstm_model(X_val)\n",
    "        y_pred = y_pred.squeeze()\n",
    "\n",
    "    # Append predictions and targets to lists\n",
    "    lstm_all_predictions.append(y_pred)\n",
    "    lstm_all_targets.append(y_val)\n",
    "\n",
    "# Concatenate the predictions and targets tensors\n",
    "lstm_all_predictions = torch.cat(lstm_all_predictions, dim=0)\n",
    "lstm_all_targets = torch.cat(lstm_all_targets, dim=0)\n",
    "\n",
    "# Flatten the predictions and targets\n",
    "y_true = lstm_all_targets.cpu().numpy().flatten()\n",
    "y_pred = lstm_all_predictions.cpu().numpy().flatten()\n",
    "threshold = 0.5  # Set the threshold for classification\n",
    "y_pred_binary = np.where(y_pred >= threshold, 1, 0)\n",
    "\n",
    "# Calculate AUC and F1 score\n",
    "auc = roc_auc_score(y_true, y_pred_binary)\n",
    "f1 = f1_score(y_true, y_pred_binary)\n",
    "\n",
    "# Print the AUC and F1 score\n",
    "print(f\"AUC: {auc:.4f}, F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5200, F1 Score: 0.3867\n",
      "Confusion Matrix:\n",
      "[[102070  97469]\n",
      " [ 38160  42761]]\n",
      "Precision: 0.3049\n",
      "Recall: 0.5284\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "y_true = lstm_all_targets.cpu().numpy()\n",
    "threshold = 0.5  # Set the threshold for classification\n",
    "y_pred_binary = np.where(lstm_all_predictions.cpu() >= threshold, 1, 0)\n",
    "# Convert y_true to int\n",
    "y_true = y_true.astype(int)\n",
    "# flatten y_true and y_pred_binary\n",
    "y_true = y_true.flatten()\n",
    "y_pred_binary = y_pred_binary.flatten()\n",
    "confusion_mat = confusion_matrix(y_true, y_pred_binary)\n",
    "precision = precision_score(y_true, y_pred_binary)\n",
    "recall = recall_score(y_true, y_pred_binary)\n",
    "\n",
    "# Print the AUC, F1 score, confusion matrix, precision, and recall\n",
    "print(f\"AUC: {auc:.4f}, F1 Score: {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"models/lstm_model_3h\"\n",
    "torch.save(lstm_model.state_dict(), save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
